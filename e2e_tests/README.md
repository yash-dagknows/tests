# End-to-End (E2E) Test Suite

Comprehensive E2E testing for DagKnows application covering both API and UI testing.

## ğŸ¯ **Overview**

This test suite focuses on **End-to-End workflows** rather than isolated unit tests. It validates complete user journeys from start to finish.

### **Test Coverage:**
- âœ… **5+ API-based E2E tests** - Testing backend workflows via API
- âœ… **5+ UI-based E2E tests** - Testing user workflows via UI automation
- âœ… **Reusable modules** - Login, authentication, common actions
- âœ… **Page Object Model** - Maintainable UI test structure
- âœ… **Real authentication** - Uses actual JWT tokens

---

## ğŸ“ **Directory Structure**

```
e2e_tests/
â”œâ”€â”€ README.md              # This file
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ package.json           # Playwright dependencies
â”œâ”€â”€ playwright.config.js   # Playwright configuration
â”œâ”€â”€ pytest.ini             # Pytest configuration
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ env.py            # Environment configuration (URLs, tokens)
â”‚   â””â”€â”€ test_users.py     # Test user credentials
â”‚
â”œâ”€â”€ fixtures/
â”‚   â”œâ”€â”€ api_client.py     # Reusable API client
â”‚   â”œâ”€â”€ auth.py           # Authentication helpers
â”‚   â””â”€â”€ test_data.py      # Test data generators
â”‚
â”œâ”€â”€ pages/                 # Page Object Model for UI tests
â”‚   â”œâ”€â”€ base_page.py      # Base page class
â”‚   â”œâ”€â”€ login_page.py     # Login page
â”‚   â”œâ”€â”€ dashboard_page.py # Dashboard/home page
â”‚   â”œâ”€â”€ task_page.py      # Task creation/management
â”‚   â””â”€â”€ chat_page.py      # AI chat session
â”‚
â”œâ”€â”€ api_tests/             # API-based E2E tests
â”‚   â”œâ”€â”€ test_task_lifecycle.py
â”‚   â”œâ”€â”€ test_alert_workflow.py
â”‚   â”œâ”€â”€ test_user_management.py
â”‚   â”œâ”€â”€ test_workspace_operations.py
â”‚   â””â”€â”€ test_incident_response.py
â”‚
â”œâ”€â”€ ui_tests/              # UI-based E2E tests
â”‚   â”œâ”€â”€ test_login_flow.py
â”‚   â”œâ”€â”€ test_task_creation.py
â”‚   â”œâ”€â”€ test_ai_chat_session.py
â”‚   â”œâ”€â”€ test_runbook_execution.py
â”‚   â””â”€â”€ test_alert_management_ui.py
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ helpers.py        # Common utility functions
â”‚   â”œâ”€â”€ wait_conditions.py # Custom wait conditions
â”‚   â””â”€â”€ api_helpers.py    # API utility functions
â”‚
â””â”€â”€ reports/              # Test reports (generated)
    â””â”€â”€ screenshots/      # Test screenshots
```

---

## ğŸš€ **Quick Start**

### **âš¡ One-Command Installation (Recommended)**

```bash
cd tests/e2e_tests
./install.sh
```

This installs everything: system dependencies, Python packages, Playwright browsers, and project structure.  
ğŸ“– See [ONE_COMMAND_INSTALL.md](ONE_COMMAND_INSTALL.md) for details.

### **1. Manual Installation (Alternative)**

```bash
cd tests/e2e_tests

# Install system dependencies (Ubuntu/Debian)
sudo apt-get install -y $(cat system_requirements.txt | grep -v '^#')

# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install Python dependencies
pip install -r requirements.txt

# Install Playwright browsers
playwright install chromium

# Setup project structure
./setup.sh
```

### **2. Configure Environment**

The `.env` file is **auto-created** by `install.sh` and pre-configured for `dev.dagknows.com`.

If you need to modify it:

```bash
# .env (already configured)
DAGKNOWS_URL=https://dev.dagknows.com
DAGKNOWS_PROXY=?proxy=dev1
DAGKNOWS_TOKEN=<auto-set-with-valid-jwt>
TEST_USER_EMAIL=yash+user@dagknows.com
TEST_USER_PASSWORD=<auto-set>
TEST_ORG=dagknows
```

ğŸ“– See [LOCAL_VS_DEV_CONFIG.md](LOCAL_VS_DEV_CONFIG.md) for local setup details.

### **3. Run Tests**

```bash
# Activate virtual environment first!
source venv/bin/activate

# Quick test - AI Agent workflow (recommended)
./run_ai_agent_test.sh

# Run all UI tests
pytest ui_tests/ -v

# Run all API tests
pytest api_tests/ -v

# Run specific test
pytest ui_tests/test_ai_agent_workflow.py -v

# Run with headed browser (for debugging)
pytest ui_tests/ --headed --slowmo 1000

# Run and generate HTML report
pytest --html=reports/report.html
```

ğŸ“– Quick guides: [RUN_NOW.md](RUN_NOW.md) | [QUICK_SETUP_GUIDE.md](QUICK_SETUP_GUIDE.md)

---

## ğŸ¯ **API-based E2E Tests**

### **Test 1: Task Lifecycle**
**File:** `api_tests/test_task_lifecycle.py`
**Flow:**
1. Create a task via API
2. Update task details
3. Add child tasks
4. Execute the task
5. Verify execution status
6. Delete task

### **Test 2: Alert to Task Execution Workflow**
**File:** `api_tests/test_alert_workflow.py`
**Flow:**
1. Create task with alert trigger
2. Send alert via processAlert API
3. Verify task is triggered
4. Check job execution status
5. Verify job completion

### **Test 3: User Management Workflow**
**File:** `api_tests/test_user_management.py`
**Flow:**
1. Create new user
2. Assign roles/permissions
3. User logs in
4. User creates workspace
5. User invites team member

### **Test 4: Workspace Operations**
**File:** `api_tests/test_workspace_operations.py`
**Flow:**
1. Create workspace
2. Add members
3. Create tasks in workspace
4. Share tasks
5. Delete workspace

### **Test 5: Incident Response Workflow**
**File:** `api_tests/test_incident_response.py`
**Flow:**
1. Set incident response mode
2. Trigger alert
3. Verify automated response
4. Check investigation tasks created
5. Validate incident closure

---

## ğŸ–¥ï¸ **UI-based E2E Tests**

### **Test 1: Complete Login Flow**
**File:** `ui_tests/test_login_flow.py`
**Flow:**
1. Navigate to login page
2. Enter credentials
3. Verify redirect to dashboard
4. Verify user menu visible
5. Logout

### **Test 2: Task Creation and Management**
**File:** `ui_tests/test_task_creation.py`
**Flow:**
1. Login
2. Click "Create Runbook"
3. Fill task details
4. Add description
5. Add child tasks
6. Verify task created
7. Edit task
8. Delete task

### **Test 3: AI Chat Session**
**File:** `ui_tests/test_ai_chat_session.py`
**Flow:**
1. Login
2. Navigate to AI chat
3. Start new session
4. Send prompt
5. Verify AI response
6. Continue conversation
7. Save/export chat

### **Test 4: Runbook Execution**
**File:** `ui_tests/test_runbook_execution.py`
**Flow:**
1. Login
2. Open existing runbook
3. Click execute
4. Monitor execution progress
5. Verify task completion
6. Check execution logs

### **Test 5: Alert Management UI**
**File:** `ui_tests/test_alert_management_ui.py`
**Flow:**
1. Login
2. Navigate to alerts page
3. View incoming alerts
4. Configure alert routing
5. Test alert handling
6. Verify task execution

---

## ğŸ”§ **Configuration**

### **Environment Variables**

| Variable | Description | Example |
|----------|-------------|---------|
| `DAGKNOWS_URL` | Base URL of deployment | `https://dev.dagknows.com` |
| `DAGKNOWS_TOKEN` | JWT access token | `eyJhbGci...` |
| `TEST_USER_EMAIL` | Test user email | `test@dagknows.com` |
| `TEST_USER_PASSWORD` | Test user password | `password123` |
| `TEST_ORG` | Organization name | `dagknows` |
| `PROXY_PARAM` | Proxy parameter for dev | `?proxy=dev1` |

### **Test User Setup**

Test users should have:
- âœ… Admin/Supremo role
- âœ… Access to test workspace
- âœ… Permissions for all operations
- âœ… Valid JWT token with long expiry

---

## ğŸ§© **Reusable Modules**

### **Authentication Module**
```python
from fixtures.auth import AuthHelper

auth = AuthHelper()
auth.login(email, password)
token = auth.get_token()
```

### **API Client Module**
```python
from fixtures.api_client import DagKnowsAPIClient

client = DagKnowsAPIClient(base_url, token)
response = client.create_task(task_data)
```

### **Page Objects**
```python
from pages.login_page import LoginPage

login_page = LoginPage(page)
login_page.login(email, password)
```

---

## ğŸ“Š **Test Reports**

### **Generate Reports**

```bash
# HTML report
pytest --html=reports/report.html --self-contained-html

# JUnit XML (for CI/CD)
pytest --junitxml=reports/junit.xml

# Allure report
pytest --alluredir=reports/allure
allure serve reports/allure
```

### **Screenshots**

Screenshots are automatically captured:
- âœ… On test failure
- âœ… At key checkpoints
- âœ… Saved in `reports/screenshots/`

---

## ğŸ“ **Best Practices**

### **1. Tests Match Real UI Behavior**
```python
# âœ… GOOD: Match how UI actually works
client.update_task(
    task_id=task_id,
    data=full_task_object,  # Send all fields
    update_mask=["title", "description", "script"]  # Like UI does
)

# âŒ BAD: Minimal update that doesn't match UI
client.update_task(
    task_id=task_id,
    data={"title": "New Title"},  # Too minimal
    update_mask=["title"]
)
```

### **2. Use Page Object Model**
```python
# âœ… GOOD: Use page objects
task_page.create_task(title, description)

# âŒ BAD: Direct element interaction
page.fill("#task-title", title)
page.fill("#task-desc", description)
```

### **3. Test Complete Workflows**
```python
# âœ… GOOD: End-to-end flow
def test_alert_to_task_execution():
    # Create task with trigger
    # Send alert
    # Verify execution
    # Check results

# âŒ BAD: Testing single operation
def test_create_task():
    create_task()  # Too isolated
```

### **4. Clean Up After Tests**
```python
@pytest.fixture
def task(client):
    task = client.create_task(...)
    yield task
    client.delete_task(task.id)  # Cleanup
```

---

## ğŸ› **Troubleshooting**

### **Issue: Playwright browsers not installed**
```bash
playwright install
```

### **Issue: Authentication fails**
- Check token is not expired
- Verify token has correct permissions
- Ensure `?proxy=dev1` is used for dev.dagknows.com

### **Issue: UI tests fail to find elements**
- Check if page has loaded completely
- Verify selectors match current UI
- Add explicit waits for dynamic content

### **Issue: API tests timeout**
- Increase timeout in pytest.ini
- Check network connectivity
- Verify URL is correct

---

## ğŸ”„ **CI/CD Integration**

### **GitHub Actions Example**

```yaml
name: E2E Tests

on: [push, pull_request]

jobs:
  e2e-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      
      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: |
          cd tests/e2e_tests
          pip install -r requirements.txt
          playwright install
      
      - name: Run E2E tests
        env:
          DAGKNOWS_URL: ${{ secrets.DAGKNOWS_URL }}
          DAGKNOWS_TOKEN: ${{ secrets.DAGKNOWS_TOKEN }}
        run: |
          cd tests/e2e_tests
          pytest --html=reports/report.html
      
      - name: Upload test results
        uses: actions/upload-artifact@v2
        with:
          name: test-results
          path: tests/e2e_tests/reports/
```

---

## ğŸ“š **Additional Resources**

- **Playwright Docs**: https://playwright.dev/python/
- **Pytest Docs**: https://docs.pytest.org/
- **Page Object Model**: https://playwright.dev/python/docs/pom
- **DagKnows API Docs**: Check `/api/docs` endpoint

---

## ğŸ¯ **Test Philosophy**

> **"Test the application as users use it, not as developers built it."**

- Focus on **user journeys**, not implementation details
- Tests should **match UI behavior** exactly
- Prefer **E2E flows** over isolated operations
- **Don't change code** to fit tests - adapt tests to code

---

**Ready to test? Start with the Quick Start section!** ğŸš€

